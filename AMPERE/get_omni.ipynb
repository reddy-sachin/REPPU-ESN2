{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load IGRF coefficients ...\n"
     ]
    }
   ],
   "source": [
    "from hapiclient import hapi, hapitime2datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import calendar\n",
    "from geopack import geopack\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_omni_data(params,data, start, stop):\n",
    "    server      = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "    dataset     = data\n",
    "    parameters  = params\n",
    "    data, meta  = hapi(server, dataset, parameters, start, stop)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data, params):\n",
    "\n",
    "    header = params.split(',')\n",
    "    header.insert(0, 'Timestamp')\n",
    "\n",
    "    #extract the data from the list\n",
    "    extracted_data = [[x[i] for x in data] for i in range(len(header))]\n",
    "\n",
    "    #create a dictionary and convert to dataframe using param names as headers\n",
    "    df_dict = {header: values for header, values in zip(header, extracted_data)}\n",
    "    df = pd.DataFrame(df_dict).set_index('Timestamp')\n",
    "\n",
    "    #convert to datetime from '\\b' time\n",
    "    df.index = hapitime2datetime(df.index.values.astype(str))\n",
    "    df.index = df.index.tz_convert(\"UTC\").tz_convert(None)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_omni_1min(data, params):\n",
    "\n",
    "    df = extract_data(data, params)\n",
    "    df['Timestamp_1min_omni'] = df.index\n",
    "    df['Timestamp_1hr_omni'] = pd.to_datetime(df['Timestamp_1min_omni'], errors='coerce').dt.floor('1h')\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_omni_1hr(params, data):\n",
    "\n",
    "    df = extract_data(data, params)\n",
    "\n",
    "    df['Timestamp_1hr_omni'] = df.index\n",
    "    df['Timestamp_1hr_omni'] = pd.to_datetime(df['Timestamp_1hr_omni'], errors='coerce').dt.floor('1h')\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2010 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BX_GSE</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>AU_INDEX</th>\n",
       "      <th>SYM_H</th>\n",
       "      <th>ASY_H</th>\n",
       "      <th>Timestamp_1min_omni</th>\n",
       "      <th>Timestamp_1hr_omni</th>\n",
       "      <th>F10.7</th>\n",
       "      <th>Kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>2.98</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>283.200012</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>72.699997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>283.200012</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-01-01 00:01:00</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>72.699997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.14</td>\n",
       "      <td>2.99</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>283.899994</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>72.699997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>3.01</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>283.899994</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-01-01 00:03:00</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>72.699997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>283.799988</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-01-01 00:04:00</td>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>72.699997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525595</th>\n",
       "      <td>-3.99</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-36</td>\n",
       "      <td>10</td>\n",
       "      <td>-17</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-12-31 23:55:00</td>\n",
       "      <td>2010-12-31 23:00:00</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525596</th>\n",
       "      <td>-3.51</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-35</td>\n",
       "      <td>10</td>\n",
       "      <td>-17</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-31 23:56:00</td>\n",
       "      <td>2010-12-31 23:00:00</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525597</th>\n",
       "      <td>-1.79</td>\n",
       "      <td>3.54</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-35</td>\n",
       "      <td>9</td>\n",
       "      <td>-17</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-12-31 23:57:00</td>\n",
       "      <td>2010-12-31 23:00:00</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525598</th>\n",
       "      <td>9999.99</td>\n",
       "      <td>9999.99</td>\n",
       "      <td>9999.99</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-35</td>\n",
       "      <td>9</td>\n",
       "      <td>-17</td>\n",
       "      <td>9</td>\n",
       "      <td>2010-12-31 23:58:00</td>\n",
       "      <td>2010-12-31 23:00:00</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525599</th>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-36</td>\n",
       "      <td>10</td>\n",
       "      <td>-17</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-31 23:59:00</td>\n",
       "      <td>2010-12-31 23:00:00</td>\n",
       "      <td>87.900002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525600 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BX_GSE   BY_GSE   BZ_GSE    flow_speed  proton_density  AL_INDEX  \\\n",
       "0          0.02     2.98    -0.39    283.200012            3.85        -1   \n",
       "1          0.13     2.96    -0.51    283.200012            3.85        -1   \n",
       "2          0.14     2.99    -0.37    283.899994            3.92        -1   \n",
       "3          0.04     3.01    -0.23    283.899994            3.92        -1   \n",
       "4          0.07     3.00    -0.46    283.799988            4.02        -2   \n",
       "...         ...      ...      ...           ...             ...       ...   \n",
       "525595    -3.99     2.04     0.42  99999.900000          999.99       -36   \n",
       "525596    -3.51     2.68    -0.65  99999.900000          999.99       -35   \n",
       "525597    -1.79     3.54    -2.06  99999.900000          999.99       -35   \n",
       "525598  9999.99  9999.99  9999.99  99999.900000          999.99       -35   \n",
       "525599    -1.41     3.69    -2.45  99999.900000          999.99       -36   \n",
       "\n",
       "        AU_INDEX  SYM_H  ASY_H Timestamp_1min_omni  Timestamp_1hr_omni  \\\n",
       "0              3      1     10 2010-01-01 00:00:00 2010-01-01 00:00:00   \n",
       "1              3      1     10 2010-01-01 00:01:00 2010-01-01 00:00:00   \n",
       "2              3      1     10 2010-01-01 00:02:00 2010-01-01 00:00:00   \n",
       "3              3      1     10 2010-01-01 00:03:00 2010-01-01 00:00:00   \n",
       "4              3      1     10 2010-01-01 00:04:00 2010-01-01 00:00:00   \n",
       "...          ...    ...    ...                 ...                 ...   \n",
       "525595        10    -17      9 2010-12-31 23:55:00 2010-12-31 23:00:00   \n",
       "525596        10    -17      8 2010-12-31 23:56:00 2010-12-31 23:00:00   \n",
       "525597         9    -17      9 2010-12-31 23:57:00 2010-12-31 23:00:00   \n",
       "525598         9    -17      9 2010-12-31 23:58:00 2010-12-31 23:00:00   \n",
       "525599        10    -17      8 2010-12-31 23:59:00 2010-12-31 23:00:00   \n",
       "\n",
       "            F10.7  Kp  \n",
       "0       72.699997   0  \n",
       "1       72.699997   0  \n",
       "2       72.699997   0  \n",
       "3       72.699997   0  \n",
       "4       72.699997   0  \n",
       "...           ...  ..  \n",
       "525595  87.900002   3  \n",
       "525596  87.900002   3  \n",
       "525597  87.900002   3  \n",
       "525598  87.900002   3  \n",
       "525599  87.900002   3  \n",
       "\n",
       "[525600 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni_1min = \"OMNI_HRO_1MIN\"\n",
    "#omni_1min_params = 'percent_interp,BY_GSE,BZ_GSE,flow_speed,proton_density,T,Pressure,E,Mach_num,BSN_x,BSN_y,BSN_z,SYM_H'\n",
    "omni_1min_params = 'BX_GSE,BY_GSE,BZ_GSE,flow_speed,proton_density,AL_INDEX,AU_INDEX,SYM_H,ASY_H'\n",
    "\n",
    "\n",
    "omni_1hr = \"OMNI2_H0_MRG1HR\"\n",
    "omni_1hr_params = 'F10_INDEX1800,KP1800'\n",
    "\n",
    "#Pressure = flow pressure in nPa\n",
    "\n",
    "#yr = 2021\n",
    "months = []\n",
    "years = [2010]\n",
    "for year in years:\n",
    "    for month in range(1,13):\n",
    "\n",
    "        print('Processing: ',year, month)\n",
    "\n",
    "        _, num_days = calendar.monthrange(year, month)\n",
    "        #num_days = 1\n",
    "\n",
    "        start_time = f'{year}-{month:02d}-{1:02d}T00:00:000Z'\n",
    "        end_time = f'{year}-{month:02d}-{num_days:02d}T23:59:59Z'\n",
    "\n",
    "        #download the data then clean it\n",
    "        omni_1min_data = fetch_omni_data(omni_1min_params, omni_1min, start_time, end_time)\n",
    "        omni_1min_df = extract_omni_1min(omni_1min_data, omni_1min_params)\n",
    "\n",
    "        omni_1hr_data = fetch_omni_data(omni_1hr_params,omni_1hr, start_time, end_time)\n",
    "        omni_1hr_df = extract_omni_1hr(omni_1hr_params, omni_1hr_data)\n",
    "\n",
    "        df = pd.merge(omni_1min_df, omni_1hr_df, on='Timestamp_1hr_omni', how='left')\n",
    "        df = df.rename(columns={'F10_INDEX1800':'F10.7', 'KP1800':'Kp'})\n",
    "        months.append(df)\n",
    "\n",
    "months_df = pd.concat(months)\n",
    "\n",
    "def calculate_tilt_angle(row):\n",
    "    t0 = datetime.datetime(1970, 1, 1)\n",
    "    t1 = row['Timestamp_1min_omni']\n",
    "    tdiff = (t1 - t0).total_seconds()\n",
    "    tilt_angle = geopack.recalc(tdiff) # Calculate dipole tilt angle\n",
    "    \n",
    "    return tilt_angle\n",
    "\n",
    "#months_df['tilt_angle'] = months_df.apply(calculate_tilt_angle, axis=1)\n",
    "\n",
    "months_df = months_df.reset_index(drop=True)\n",
    "\n",
    "#export_path = f'/Users/sr2/My Drive/Career/Employment/Current/JSPS/Research/Analysis/Apr-24/data/omni/' #macbook\n",
    "#export_path = f'/home/ryuho/Documents/reddy/research/SMRAI/Data/OMNI/' #linux\n",
    "export_path = f'/home/sachin/Documents/NIPR/Research/Data/OMNI/' #server\n",
    "\n",
    "df_name = f'omni_hro_1min_2010'\n",
    "export_filename = export_path + df_name +'.csv'\n",
    "months_df.to_csv(export_filename, index=False, header=True)\n",
    "months_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_omni(df):\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "\n",
    "    #filters\n",
    "    df = df[df['BY_GSE'] < 100]\n",
    "    df = df[df['BZ_GSE'] < 100]\n",
    "    df = df[df['flow_speed'] < 1400]\n",
    "    df = df[df['proton_density'] < 150]\n",
    "    #df = df[df['T'] < 1e6]\n",
    "    #df = df[df['Pressure'] < 100]\n",
    "    #df = df[df['E'] < 100]\n",
    "    #df = df[df['Mach_num'] < 100]\n",
    "    df = df[df['SYM_H'].between(-1000,100)]\n",
    "    df = df[df['F10.7'] < 400]\n",
    "    df = df[df['Kp'] < 100]\n",
    "    df['Kp'] = df['Kp'] / 10\n",
    "\n",
    "    #change data types\n",
    "    df[['F10.7','flow_speed']] = df[['F10.7','flow_speed']].astype(int)\n",
    "\n",
    "    #new features\n",
    "    df['Timestamp_1min_omni'] = pd.to_datetime(df['Timestamp_1min_omni'])\n",
    "    df['doy'] = df['Timestamp_1min_omni'].dt.dayofyear\n",
    "    \n",
    "    def calculate_tilt_angle(row):\n",
    "        t0 = datetime.datetime(1970, 1, 1)\n",
    "        t1 = row['Timestamp_1min_omni']\n",
    "        tdiff = (t1 - t0).total_seconds()\n",
    "        tilt_angle = geopack.recalc(tdiff) # Calculate dipole tilt angle\n",
    "        \n",
    "        return tilt_angle\n",
    "    \n",
    "    #df['tilt_angle'] = df.apply(calculate_tilt_angle, axis=1)\n",
    "\n",
    "    #interpolate missing values\n",
    "    df = df.interpolate()\n",
    "    #df = df.drop(columns=['percent_interp','Timestamp_1hr_omni','BSN_y','BSN_z'])\n",
    "\n",
    "    #match SMRAI2 inputs\n",
    "    #df = df.drop(columns=['BSN_x','SYM_H','doy','T','Pressure','E','Mach_num','SYM_H','F10.7','Kp'])\n",
    "    return df.to_csv(export_filename, index=False, header=True)\n",
    "\n",
    "omni_df = clean_omni(months_df)\n",
    "omni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show nan values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read MHD dates and expand-out the date ranges\n",
    "mhd_data = pd.read_csv('mhd_dates.csv')\n",
    "expanded_dt = pd.concat([pd.Series(pd.date_range(start, end)) \n",
    "        for start, end in zip(mhd_data['start'], mhd_data['end'])])\n",
    "\n",
    "time = np.arange(288) #24hrs in 5min intervals\n",
    "dt = [] \n",
    "for day in expanded_dt:\n",
    "    for t in time:\n",
    "        dt.append(day + pd.Timedelta(minutes=t*5)) #add 5min intervals to each day\n",
    "dt = np.array(dt) #convert from list to numpy array\n",
    "mhd_dates = pd.DataFrame({'Timestamp_1min_omni': dt}) \n",
    "mhd_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_mhd_dt_merged = pd.merge(mhd_dates, omni_df, on='Timestamp_1min_omni', how='left')\n",
    "omni_mhd_dt_merged.rename(columns={'Timestamp_1min_omni':'dt'}, inplace=True)\n",
    "omni_mhd_dt_merged.sort_values(by='dt', inplace=True)\n",
    "#omni_mhd_dt_merged =omni_mhd_dt_merged.interpolate()\n",
    "#check for nan values\n",
    "omni_mhd_dt_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "omni_mhd_dt_merged = pd.merge(mhd_dates, omni_df, on='Timestamp_1min_omni', how='left')\n",
    "omni_mhd_dt_merged.rename(columns={'Timestamp_1min_omni': 'dt'}, inplace=True)\n",
    "omni_mhd_dt_merged.sort_values(by='dtinterpolated\n",
    "', inplace=True)\n",
    "\n",
    "# Interpolate missing values\n",
    "omni_mhd_dt_merged['interpolated'] = omni_mhd_dt_merged.isnull().any(axis=1).astype(int)\n",
    "omni_mhd_dt_merged = omni_mhd_dt_merged.interpolate()\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(nrows=len(omni_mhd_dt_merged.columns[1:-1]), ncols=1, figsize=(10, 2 * len(omni_mhd_dt_merged.columns[1:-1])), sharex=True)\n",
    "for i, column in enumerate(omni_mhd_dt_merged.columns[1:-1]):\n",
    "    axes[i].plot(omni_mhd_dt_merged['dt'], omni_mhd_dt_merged[column], label=column)\n",
    "    axes[i].scatter(omni_mhd_dt_merged['dt'][omni_mhd_dt_merged['interpolated'] == 1], omni_mhd_dt_merged[column][omni_mhd_dt_merged['interpolated'] == 1], color='red', label='Interpolated')\n",
    "    axes[i].set_ylabel(column)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export omni_mhd_dt_merged\n",
    "#export_path = f'/Users/sr2/My Drive/Career/Employment/Current/JSPS/Research/Analysis/Apr-24/data/omni/'\n",
    "#export_path = f'/home/sachin/Documents/NIPR/Research/VSCode/REPPU-ESN2/SR_ML/'\n",
    "df_name = f'omni_add-feats_mhd_5min'\n",
    "#export_filename = export_path + df_name +'.csv'\n",
    "export_filename = df_name +'.csv'\n",
    "omni_mhd_dt_merged.to_csv(export_filename, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show nan values\n",
    "nan_values = omni_mhd_dt_merged[omni_mhd_dt_merged.isna().any(axis=1)]\n",
    "nan_values.sort_values(by='dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots are below. Not part of main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "omni_df.hist(ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = omni_df['doy']\n",
    "x = omni_df['tilt_angle']\n",
    "r2 = x.corr(y)\n",
    "sns.jointplot(x=x, y=y, kind='scatter', s=1, height=4.5)\n",
    "RE = r'R$_E$'\n",
    "pcc = r'cm$^{-3}$'\n",
    "#plt.xlabel(f'Proton Density [{pcc}]')\n",
    "#plt.ylabel(f'Bow Shock Nose Location (GSE-X) [{RE}]')\n",
    "#plt.xlabel('Pressure [nPa]')\n",
    "\n",
    "#plt.ylabel('Electric Field [mV/m]')\n",
    "#plt.xlabel('Bz [nT]')\n",
    "\n",
    "r2_lab = r'R$^2$'    \n",
    "annotation = f'{r2_lab} = {r2:.2f}'\n",
    "plt.annotate(annotation, xy=(0.75, 0.7), xycoords='axes fraction', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/sr2/OneDrive - University College London/PhD/Experiences/Postdocs/JSPS/Research/Analysis/Apr-24/plots/omni/R2_tilt-angle_doy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = omni_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(7.5, 6.5))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmin=-1, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .7}, annot=True,\n",
    "             fmt=\".2f\")\n",
    "\n",
    "plt.title('OMNI 5min Data Correlation Matrix \\n January 2021 - December 2022',pad=-40)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/Users/sr2/OneDrive - University College London/PhD/Experiences/Postdocs/JSPS/Research/Analysis/Apr-24/plots/omni/omni_heatmap.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(omni_mhd_dt_merged['flow_speed'], bins=50)\n",
    "omni_mhd_dt_merged['flow_speed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(omni_df.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, fmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
