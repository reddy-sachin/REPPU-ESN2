{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load IGRF coefficients ...\n"
     ]
    }
   ],
   "source": [
    "from hapiclient import hapi, hapitime2datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import calendar\n",
    "from geopack import geopack\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_omni_data(params,data, start, stop):\n",
    "    server      = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "    dataset     = data\n",
    "    parameters  = params\n",
    "    data, meta  = hapi(server, dataset, parameters, start, stop)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data, params):\n",
    "\n",
    "    header = params.split(',')\n",
    "    header.insert(0, 'Timestamp')\n",
    "\n",
    "    #extract the data from the list\n",
    "    extracted_data = [[x[i] for x in data] for i in range(len(header))]\n",
    "\n",
    "    #create a dictionary and convert to dataframe using param names as headers\n",
    "    df_dict = {header: values for header, values in zip(header, extracted_data)}\n",
    "    df = pd.DataFrame(df_dict).set_index('Timestamp')\n",
    "\n",
    "    #convert to datetime from '\\b' time\n",
    "    df.index = hapitime2datetime(df.index.values.astype(str))\n",
    "    df.index = df.index.tz_convert(\"UTC\").tz_convert(None)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_omni_1min(data, params):\n",
    "\n",
    "    df = extract_data(data, params)\n",
    "    df['Timestamp_1min_omni'] = df.index\n",
    "    df['Timestamp_2min_omni'] = pd.to_datetime(df['Timestamp_1min_omni'], errors='coerce').dt.floor('2min')\n",
    "    df['Timestamp_1hr_omni'] = pd.to_datetime(df['Timestamp_1min_omni'], errors='coerce').dt.floor('1h')\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_omni_1hr(params, data):\n",
    "\n",
    "    df = extract_data(data, params)\n",
    "\n",
    "    df['Timestamp_1hr_omni'] = df.index\n",
    "    df['Timestamp_1hr_omni'] = pd.to_datetime(df['Timestamp_1hr_omni'], errors='coerce').dt.floor('1h')\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  2013 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/hapiclient/hapitime.py:287: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  Time = pandas.to_datetime(Time, infer_datetime_format=True).tz_convert(tzinfo).to_pydatetime()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BX_GSE</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>AU_INDEX</th>\n",
       "      <th>SYM_H</th>\n",
       "      <th>ASY_H</th>\n",
       "      <th>Timestamp_1min_omni</th>\n",
       "      <th>Timestamp_2min_omni</th>\n",
       "      <th>Timestamp_1hr_omni</th>\n",
       "      <th>F10.7</th>\n",
       "      <th>Kp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.42</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>358.799988</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113.900002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.42</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>358.799988</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-01-01 00:01:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113.900002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.42</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>358.799988</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-01-01 00:02:00</td>\n",
       "      <td>2013-01-01 00:02:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113.900002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.33</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>359.299988</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2013-01-01 00:03:00</td>\n",
       "      <td>2013-01-01 00:02:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113.900002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.31</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>358.799988</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2013-01-01 00:04:00</td>\n",
       "      <td>2013-01-01 00:04:00</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113.900002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525595</th>\n",
       "      <td>-1.29</td>\n",
       "      <td>4.20</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>385.100006</td>\n",
       "      <td>5.36</td>\n",
       "      <td>-4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-31 23:55:00</td>\n",
       "      <td>2013-12-31 23:54:00</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525596</th>\n",
       "      <td>-1.30</td>\n",
       "      <td>4.16</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>385.100006</td>\n",
       "      <td>5.36</td>\n",
       "      <td>-4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-31 23:56:00</td>\n",
       "      <td>2013-12-31 23:56:00</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525597</th>\n",
       "      <td>-1.43</td>\n",
       "      <td>4.21</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-31 23:57:00</td>\n",
       "      <td>2013-12-31 23:56:00</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525598</th>\n",
       "      <td>-1.11</td>\n",
       "      <td>4.18</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>384.200012</td>\n",
       "      <td>5.64</td>\n",
       "      <td>-5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-31 23:58:00</td>\n",
       "      <td>2013-12-31 23:58:00</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525599</th>\n",
       "      <td>-1.06</td>\n",
       "      <td>4.35</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>99999.900000</td>\n",
       "      <td>999.99</td>\n",
       "      <td>-5</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-12-31 23:59:00</td>\n",
       "      <td>2013-12-31 23:58:00</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525600 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BX_GSE  BY_GSE  BZ_GSE    flow_speed  proton_density  AL_INDEX  \\\n",
       "0         2.42   -0.35   -0.09    358.799988            1.94        -4   \n",
       "1         2.42   -0.38   -0.09    358.799988            1.94        -5   \n",
       "2         2.42   -0.33   -0.14    358.799988            1.94        -6   \n",
       "3         2.33   -0.64   -0.07    359.299988            1.94        -6   \n",
       "4         2.31   -0.72   -0.16    358.799988            1.95        -5   \n",
       "...        ...     ...     ...           ...             ...       ...   \n",
       "525595   -1.29    4.20   -2.46    385.100006            5.36        -4   \n",
       "525596   -1.30    4.16   -2.64    385.100006            5.36        -4   \n",
       "525597   -1.43    4.21   -2.56  99999.900000          999.99        -4   \n",
       "525598   -1.11    4.18   -2.67    384.200012            5.64        -5   \n",
       "525599   -1.06    4.35   -2.32  99999.900000          999.99        -5   \n",
       "\n",
       "        AU_INDEX  SYM_H  ASY_H Timestamp_1min_omni Timestamp_2min_omni  \\\n",
       "0              5      1     12 2013-01-01 00:00:00 2013-01-01 00:00:00   \n",
       "1              4      1     12 2013-01-01 00:01:00 2013-01-01 00:00:00   \n",
       "2              3      1     12 2013-01-01 00:02:00 2013-01-01 00:02:00   \n",
       "3              3      2     13 2013-01-01 00:03:00 2013-01-01 00:02:00   \n",
       "4              4      2     11 2013-01-01 00:04:00 2013-01-01 00:04:00   \n",
       "...          ...    ...    ...                 ...                 ...   \n",
       "525595        13      2      2 2013-12-31 23:55:00 2013-12-31 23:54:00   \n",
       "525596        12      2      2 2013-12-31 23:56:00 2013-12-31 23:56:00   \n",
       "525597        11      3      2 2013-12-31 23:57:00 2013-12-31 23:56:00   \n",
       "525598        11      2      3 2013-12-31 23:58:00 2013-12-31 23:58:00   \n",
       "525599        11      3      2 2013-12-31 23:59:00 2013-12-31 23:58:00   \n",
       "\n",
       "        Timestamp_1hr_omni       F10.7  Kp  \n",
       "0      2013-01-01 00:00:00  113.900002   7  \n",
       "1      2013-01-01 00:00:00  113.900002   7  \n",
       "2      2013-01-01 00:00:00  113.900002   7  \n",
       "3      2013-01-01 00:00:00  113.900002   7  \n",
       "4      2013-01-01 00:00:00  113.900002   7  \n",
       "...                    ...         ...  ..  \n",
       "525595 2013-12-31 23:00:00  140.500000   7  \n",
       "525596 2013-12-31 23:00:00  140.500000   7  \n",
       "525597 2013-12-31 23:00:00  140.500000   7  \n",
       "525598 2013-12-31 23:00:00  140.500000   7  \n",
       "525599 2013-12-31 23:00:00  140.500000   7  \n",
       "\n",
       "[525600 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omni_1min = \"OMNI_HRO_1MIN\"\n",
    "#omni_1min_params = 'percent_interp,BY_GSE,BZ_GSE,flow_speed,proton_density,T,Pressure,E,Mach_num,BSN_x,BSN_y,BSN_z,SYM_H'\n",
    "omni_1min_params = 'BX_GSE,BY_GSE,BZ_GSE,flow_speed,proton_density,AL_INDEX,AU_INDEX,SYM_H,ASY_H'\n",
    "\n",
    "\n",
    "omni_1hr = \"OMNI2_H0_MRG1HR\"\n",
    "omni_1hr_params = 'F10_INDEX1800,KP1800'\n",
    "\n",
    "#Pressure = flow pressure in nPa\n",
    "\n",
    "#yr = 2021\n",
    "months = []\n",
    "years = [2013]\n",
    "for year in years:\n",
    "    for month in range(1,13):\n",
    "\n",
    "        print('Processing: ',year, month)\n",
    "\n",
    "        _, num_days = calendar.monthrange(year, month)\n",
    "        #num_days = 1\n",
    "\n",
    "        start_time = f'{year}-{month:02d}-{1:02d}T00:00:000Z'\n",
    "        end_time = f'{year}-{month:02d}-{num_days:02d}T23:59:59Z'\n",
    "\n",
    "        #download the data then clean it\n",
    "        omni_1min_data = fetch_omni_data(omni_1min_params, omni_1min, start_time, end_time)\n",
    "        omni_1min_df = extract_omni_1min(omni_1min_data, omni_1min_params)\n",
    "\n",
    "        omni_1hr_data = fetch_omni_data(omni_1hr_params,omni_1hr, start_time, end_time)\n",
    "        omni_1hr_df = extract_omni_1hr(omni_1hr_params, omni_1hr_data)\n",
    "\n",
    "        df = pd.merge(omni_1min_df, omni_1hr_df, on='Timestamp_1hr_omni', how='left')\n",
    "        df = df.rename(columns={'F10_INDEX1800':'F10.7', 'KP1800':'Kp'})\n",
    "        months.append(df)\n",
    "\n",
    "months_df = pd.concat(months)\n",
    "\n",
    "def calculate_tilt_angle(row):\n",
    "    t0 = datetime.datetime(1970, 1, 1)\n",
    "    t1 = row['Timestamp_1min_omni']\n",
    "    tdiff = (t1 - t0).total_seconds()\n",
    "    tilt_angle = geopack.recalc(tdiff) # Calculate dipole tilt angle\n",
    "    \n",
    "    return tilt_angle\n",
    "\n",
    "#months_df['tilt_angle'] = months_df.apply(calculate_tilt_angle, axis=1)\n",
    "\n",
    "months_df = months_df.reset_index(drop=True)\n",
    "\n",
    "#export_path = f'/Users/sr2/My Drive/Career/Employment/Current/JSPS/Research/Analysis/Apr-24/data/omni/' #macbook\n",
    "#export_path = f'/home/ryuho/Documents/reddy/research/SMRAI/Data/OMNI/' #linux\n",
    "export_path = f'/home/sachin/Documents/NIPR/Research/Data/OMNI/' #server\n",
    "\n",
    "df_name = f'omni_hro_1min_2013'\n",
    "export_filename = export_path + df_name +'.csv'\n",
    "months_df.to_csv(export_filename, index=False, header=True)\n",
    "months_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp_2min_omni</th>\n",
       "      <th>BX_GSE</th>\n",
       "      <th>BY_GSE</th>\n",
       "      <th>BZ_GSE</th>\n",
       "      <th>flow_speed</th>\n",
       "      <th>proton_density</th>\n",
       "      <th>AL_INDEX</th>\n",
       "      <th>AU_INDEX</th>\n",
       "      <th>SYM_H</th>\n",
       "      <th>ASY_H</th>\n",
       "      <th>Timestamp_1min_omni</th>\n",
       "      <th>Timestamp_1hr_omni</th>\n",
       "      <th>F10.7</th>\n",
       "      <th>Kp</th>\n",
       "      <th>doy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>2.420</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>358</td>\n",
       "      <td>1.940</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2013-01-01 00:00:30</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 00:02:00</td>\n",
       "      <td>2.375</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>359</td>\n",
       "      <td>1.940</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2013-01-01 00:02:30</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 00:04:00</td>\n",
       "      <td>2.240</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>358</td>\n",
       "      <td>1.965</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2013-01-01 00:04:30</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 00:06:00</td>\n",
       "      <td>2.090</td>\n",
       "      <td>-1.005</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>361</td>\n",
       "      <td>2.065</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2013-01-01 00:06:30</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 00:08:00</td>\n",
       "      <td>2.020</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>362</td>\n",
       "      <td>2.040</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2013-01-01 00:08:30</td>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>113</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252834</th>\n",
       "      <td>2013-12-31 23:50:00</td>\n",
       "      <td>-1.130</td>\n",
       "      <td>4.240</td>\n",
       "      <td>-2.465</td>\n",
       "      <td>384</td>\n",
       "      <td>5.895</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2013-12-31 23:50:30</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0.7</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252835</th>\n",
       "      <td>2013-12-31 23:52:00</td>\n",
       "      <td>-1.080</td>\n",
       "      <td>4.240</td>\n",
       "      <td>-2.660</td>\n",
       "      <td>383</td>\n",
       "      <td>5.715</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2013-12-31 23:52:30</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0.7</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252836</th>\n",
       "      <td>2013-12-31 23:54:00</td>\n",
       "      <td>-1.105</td>\n",
       "      <td>4.170</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>384</td>\n",
       "      <td>5.490</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2013-12-31 23:54:30</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0.7</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252837</th>\n",
       "      <td>2013-12-31 23:56:00</td>\n",
       "      <td>-1.365</td>\n",
       "      <td>4.185</td>\n",
       "      <td>-2.600</td>\n",
       "      <td>384</td>\n",
       "      <td>5.430</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013-12-31 23:56:30</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0.7</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252838</th>\n",
       "      <td>2013-12-31 23:58:00</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>4.265</td>\n",
       "      <td>-2.495</td>\n",
       "      <td>384</td>\n",
       "      <td>5.640</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2013-12-31 23:58:30</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>140</td>\n",
       "      <td>0.7</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252839 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp_2min_omni  BX_GSE  BY_GSE  BZ_GSE  flow_speed  \\\n",
       "0      2013-01-01 00:00:00   2.420  -0.365  -0.090         358   \n",
       "1      2013-01-01 00:02:00   2.375  -0.485  -0.105         359   \n",
       "2      2013-01-01 00:04:00   2.240  -0.865  -0.245         358   \n",
       "3      2013-01-01 00:06:00   2.090  -1.005  -0.585         361   \n",
       "4      2013-01-01 00:08:00   2.020  -0.995  -0.680         362   \n",
       "...                    ...     ...     ...     ...         ...   \n",
       "252834 2013-12-31 23:50:00  -1.130   4.240  -2.465         384   \n",
       "252835 2013-12-31 23:52:00  -1.080   4.240  -2.660         383   \n",
       "252836 2013-12-31 23:54:00  -1.105   4.170  -2.600         384   \n",
       "252837 2013-12-31 23:56:00  -1.365   4.185  -2.600         384   \n",
       "252838 2013-12-31 23:58:00  -1.085   4.265  -2.495         384   \n",
       "\n",
       "        proton_density  AL_INDEX  AU_INDEX  SYM_H  ASY_H Timestamp_1min_omni  \\\n",
       "0                1.940      -4.5       4.5    1.0   12.0 2013-01-01 00:00:30   \n",
       "1                1.940      -6.0       3.0    1.5   12.5 2013-01-01 00:02:30   \n",
       "2                1.965      -4.5       4.0    1.5   11.5 2013-01-01 00:04:30   \n",
       "3                2.065      -5.5       4.0    1.5   12.0 2013-01-01 00:06:30   \n",
       "4                2.040      -6.0       3.0    1.0   12.0 2013-01-01 00:08:30   \n",
       "...                ...       ...       ...    ...    ...                 ...   \n",
       "252834           5.895      -6.0      13.0    2.0    2.5 2013-12-31 23:50:30   \n",
       "252835           5.715      -5.0      14.5    2.0    1.5 2013-12-31 23:52:30   \n",
       "252836           5.490      -4.0      13.5    2.0    1.5 2013-12-31 23:54:30   \n",
       "252837           5.430      -4.0      11.5    2.5    2.0 2013-12-31 23:56:30   \n",
       "252838           5.640      -5.0      11.0    2.5    2.5 2013-12-31 23:58:30   \n",
       "\n",
       "        Timestamp_1hr_omni  F10.7   Kp  doy  \n",
       "0      2013-01-01 00:00:00    113  0.7    1  \n",
       "1      2013-01-01 00:00:00    113  0.7    1  \n",
       "2      2013-01-01 00:00:00    113  0.7    1  \n",
       "3      2013-01-01 00:00:00    113  0.7    1  \n",
       "4      2013-01-01 00:00:00    113  0.7    1  \n",
       "...                    ...    ...  ...  ...  \n",
       "252834 2013-12-31 23:00:00    140  0.7  365  \n",
       "252835 2013-12-31 23:00:00    140  0.7  365  \n",
       "252836 2013-12-31 23:00:00    140  0.7  365  \n",
       "252837 2013-12-31 23:00:00    140  0.7  365  \n",
       "252838 2013-12-31 23:00:00    140  0.7  365  \n",
       "\n",
       "[252839 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_omni(df):\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "\n",
    "    #replace 99999.900000 in flow_speed with NaN then interpolate over\n",
    "    df['flow_speed'] = df['flow_speed'].replace(99999.900000, np.nan)\n",
    "    df['proton_density'] = df['proton_density'].replace(999.99, np.nan)\n",
    "    df['F10.7'] = df['F10.7'].replace(999.9, np.nan)\n",
    "    df['BX_GSE'] = df['BX_GSE'].replace(9999.99, np.nan)\n",
    "    df['BY_GSE'] = df['BY_GSE'].replace(9999.99, np.nan)\n",
    "    df['BZ_GSE'] = df['BZ_GSE'].replace(9999.99, np.nan)\n",
    "    df = df.interpolate(limit=10)\n",
    "\n",
    "    #check to see where NaNs are    \n",
    "    #df = df.set_index('Timestamp_1min_omni')\n",
    "    #msno.matrix(df, freq='M')\n",
    "    \n",
    "    #filters\n",
    "    df = df[df['flow_speed'] < 1400]\n",
    "    df = df[df['proton_density'] < 150]\n",
    "    df = df[df['F10.7'] < 400]\n",
    "    df = df[df['BX_GSE'].between(-100,100)]\n",
    "    df = df[df['BY_GSE'].between(-100,100)]\n",
    "    df = df[df['BZ_GSE'].between(-100,100)]\n",
    "    df = df[df['SYM_H'].between(-1000,100)]\n",
    "    df = df[df['ASY_H'] < 1000]\n",
    "    df = df[df['AU_INDEX'] < 2000]\n",
    "    df = df[df['AL_INDEX'] > -2000]\n",
    "    df = df[df['Kp'] < 100]\n",
    "    df['Kp'] = df['Kp'] / 10\n",
    "\n",
    "    #new feature\n",
    "    df['Timestamp_1min_omni'] = pd.to_datetime(df['Timestamp_1min_omni'])\n",
    "    df['doy'] = df['Timestamp_1min_omni'].dt.dayofyear\n",
    "\n",
    "    \n",
    "    def calculate_tilt_angle(row):\n",
    "        t0 = datetime.datetime(1970, 1, 1)\n",
    "        t1 = row['Timestamp_1min_omni']\n",
    "        tdiff = (t1 - t0).total_seconds()\n",
    "        tilt_angle = geopack.recalc(tdiff) # Calculate dipole tilt angle\n",
    "        \n",
    "        return tilt_angle\n",
    "    \n",
    "    #df['tilt_angle'] = df.apply(calculate_tilt_angle, axis=1)\n",
    "\n",
    "    #histplot of all features\n",
    "    #for index, column in enumerate(df.columns):\n",
    "    #    plt.figure(index)\n",
    "    #    sns.histplot(df[column])\n",
    "\n",
    "    df = df.groupby('Timestamp_2min_omni').mean().reset_index(drop=False)\n",
    "    df = df.sort_values(by='Timestamp_2min_omni')\n",
    "\n",
    "    #format datatypes\n",
    "    df['doy'] = df['doy'].astype(int)\n",
    "    df['F10.7'] = df['F10.7'].astype(int)\n",
    "    df['flow_speed'] = df['flow_speed'].astype(int)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "omni_df = clean_omni(months_df)\n",
    "omni_df.to_csv(export_filename, index=False, header=True)\n",
    "omni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_gaps(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    blank_date_range = pd.date_range(start='2011-01-01', end='2011-12-31', freq='2min')\n",
    "    blank_df = pd.DataFrame(blank_date_range, columns=['Timestamp_2min_omni'])\n",
    "\n",
    "    merged = pd.merge(blank_df, df, on='Timestamp_2min_omni', how='left')\n",
    "    merged = merged.drop(columns=['Timestamp_1min_omni', 'Timestamp_1hr_omni'])\n",
    "    merged = merged.set_index('Timestamp_2min_omni')\n",
    "\n",
    "    #plt.figure(figsize=(5,5))\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    msno.matrix(merged, freq='M', ax=ax)\n",
    "\n",
    "    return merged\n",
    "\n",
    "check_data_gaps(omni_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read MHD dates and expand-out the date ranges\n",
    "mhd_data = pd.read_csv('mhd_dates.csv')\n",
    "expanded_dt = pd.concat([pd.Series(pd.date_range(start, end)) \n",
    "        for start, end in zip(mhd_data['start'], mhd_data['end'])])\n",
    "\n",
    "time = np.arange(288) #24hrs in 5min intervals\n",
    "dt = [] \n",
    "for day in expanded_dt:\n",
    "    for t in time:\n",
    "        dt.append(day + pd.Timedelta(minutes=t*5)) #add 5min intervals to each day\n",
    "dt = np.array(dt) #convert from list to numpy array\n",
    "mhd_dates = pd.DataFrame({'Timestamp_1min_omni': dt}) \n",
    "mhd_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_mhd_dt_merged = pd.merge(mhd_dates, omni_df, on='Timestamp_1min_omni', how='left')\n",
    "omni_mhd_dt_merged.rename(columns={'Timestamp_1min_omni':'dt'}, inplace=True)\n",
    "omni_mhd_dt_merged.sort_values(by='dt', inplace=True)\n",
    "#omni_mhd_dt_merged =omni_mhd_dt_merged.interpolate()\n",
    "#check for nan values\n",
    "omni_mhd_dt_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "omni_mhd_dt_merged = pd.merge(mhd_dates, omni_df, on='Timestamp_1min_omni', how='left')\n",
    "omni_mhd_dt_merged.rename(columns={'Timestamp_1min_omni': 'dt'}, inplace=True)\n",
    "omni_mhd_dt_merged.sort_values(by='d, inplace=True)\n",
    "\n",
    "# Interpolate missing values\n",
    "omni_mhd_dt_merged['interpolated'] = omni_mhd_dt_merged.isnull().any(axis=1).astype(int)\n",
    "omni_mhd_dt_merged = omni_mhd_dt_merged.interpolate()\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(nrows=len(omni_mhd_dt_merged.columns[1:-1]), ncols=1, figsize=(10, 2 * len(omni_mhd_dt_merged.columns[1:-1])), sharex=True)\n",
    "for i, column in enumerate(omni_mhd_dt_merged.columns[1:-1]):\n",
    "    axes[i].plot(omni_mhd_dt_merged['dt'], omni_mhd_dt_merged[column], label=column)\n",
    "    axes[i].scatter(omni_mhd_dt_merged['dt'][omni_mhd_dt_merged['interpolated'] == 1], omni_mhd_dt_merged[column][omni_mhd_dt_merged['interpolated'] == 1], color='red', label='Interpolated')\n",
    "    axes[i].set_ylabel(column)\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export omni_mhd_dt_merged\n",
    "#export_path = f'/Users/sr2/My Drive/Career/Employment/Current/JSPS/Research/Analysis/Apr-24/data/omni/'\n",
    "#export_path = f'/home/sachin/Documents/NIPR/Research/VSCode/REPPU-ESN2/SR_ML/'\n",
    "df_name = f'omni_add-feats_mhd_5min'\n",
    "#export_filename = export_path + df_name +'.csv'\n",
    "export_filename = df_name +'.csv'\n",
    "omni_mhd_dt_merged.to_csv(export_filename, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show nan values\n",
    "nan_values = omni_mhd_dt_merged[omni_mhd_dt_merged.isna().any(axis=1)]\n",
    "nan_values.sort_values(by='dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots are below. Not part of main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "omni_df.hist(ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = omni_df['doy']\n",
    "x = omni_df['tilt_angle']\n",
    "r2 = x.corr(y)\n",
    "sns.jointplot(x=x, y=y, kind='scatter', s=1, height=4.5)\n",
    "RE = r'R$_E$'\n",
    "pcc = r'cm$^{-3}$'\n",
    "#plt.xlabel(f'Proton Density [{pcc}]')\n",
    "#plt.ylabel(f'Bow Shock Nose Location (GSE-X) [{RE}]')\n",
    "#plt.xlabel('Pressure [nPa]')\n",
    "\n",
    "#plt.ylabel('Electric Field [mV/m]')\n",
    "#plt.xlabel('Bz [nT]')\n",
    "\n",
    "r2_lab = r'R$^2$'    \n",
    "annotation = f'{r2_lab} = {r2:.2f}'\n",
    "plt.annotate(annotation, xy=(0.75, 0.7), xycoords='axes fraction', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/sr2/OneDrive - University College London/PhD/Experiences/Postdocs/JSPS/Research/Analysis/Apr-24/plots/omni/R2_tilt-angle_doy.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = omni_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(7.5, 6.5))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmin=-1, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .7}, annot=True,\n",
    "             fmt=\".2f\")\n",
    "\n",
    "plt.title('OMNI 5min Data Correlation Matrix \\n January 2021 - December 2022',pad=-40)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('/Users/sr2/OneDrive - University College London/PhD/Experiences/Postdocs/JSPS/Research/Analysis/Apr-24/plots/omni/omni_heatmap.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(omni_mhd_dt_merged['flow_speed'], bins=50)\n",
    "omni_mhd_dt_merged['flow_speed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(omni_df.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, fmt=\".2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
