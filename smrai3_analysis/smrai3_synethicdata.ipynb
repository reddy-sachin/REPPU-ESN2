{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load IGRF coefficients ...\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pickle\n",
    "import datetime as datetime\n",
    "from geopack import geopack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 40 * 140)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Use the same device as the model for hidden states\n",
    "        device = next(self.parameters()).device  # Ensure hidden states are on the same device as the model\n",
    "        \n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size, device=device)  # Initial hidden state\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size, device=device)  # Initial cell state\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = out.view(-1, 40, 140)\n",
    "        return out\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the internal states of the LSTM layer\n",
    "        self.lstm.reset_parameters()\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "lookback = 30\n",
    "\n",
    "def load_model(model_path,lookback=30):\n",
    "\n",
    "    model = LSTM(lookback, 128, 2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "#NH\n",
    "NH_sxx_model = load_model(\"/home/sachin/Documents/NIPR/Research/Data/ML/SMRAI3/smrai3_model_sxx_NH_id1.pt\") \n",
    "NH_syy_model = load_model(\"/home/sachin/Documents/NIPR/Research/Data/ML/SMRAI3/smrai3_model_syy_NH_id1.pt\")\n",
    "NH_fac_model = load_model(\"/home/sachin/Documents/NIPR/Research/Data/ML/SMRAI3/smrai3_model_fac_NH_id2.pt\")\n",
    "NH_pot_model = load_model(\"/home/sachin/Documents/NIPR/Research/Data/ML/SMRAI3/smrai3_model_pot_NH_id2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.7292050e-06, -5.0263020e-06,  7.5579158e-07, ...,\n",
       "         3.8376347e-06, -7.7109235e-09, -6.9203647e-06],\n",
       "       [-1.0091458e-05, -3.8744211e-06,  4.8234979e-06, ...,\n",
       "         4.4408271e-06, -8.1209134e-07, -5.2599444e-07],\n",
       "       [-1.9286042e-06,  3.4293321e-06,  6.1533760e-06, ...,\n",
       "         1.6481009e-06,  7.7711702e-06,  3.2767707e-07],\n",
       "       ...,\n",
       "       [ 6.2919758e-02,  6.1496563e-02,  6.0130842e-02, ...,\n",
       "         6.7778043e-02,  6.6637248e-02,  6.5606825e-02],\n",
       "       [ 6.5856159e-02,  6.5268993e-02,  6.4165093e-02, ...,\n",
       "         7.1575418e-02,  7.0035227e-02,  6.9551580e-02],\n",
       "       [ 7.1083128e-02,  7.0191190e-02,  6.9533013e-02, ...,\n",
       "         7.1244352e-02,  7.1684420e-02,  7.1505845e-02]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(model, feat, hemi, By, Bz, id):\n",
    "    \n",
    "    flow_speed = 450\n",
    "    proton_density = 5\n",
    "    tilt = 0\n",
    "\n",
    "    BY_arr = np.repeat(By, lookback+1)\n",
    "    BZ_arr = np.repeat(Bz, lookback+1)\n",
    "    flow_speed_arr = np.repeat(flow_speed, lookback+1)\n",
    "    proton_density_arr = np.repeat(proton_density, lookback+1)\n",
    "    tilt_angle_arr = np.repeat(tilt, lookback+1)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'BY': BY_arr, 'BZ': BZ_arr, 'flow_speed': flow_speed_arr,'proton_density': proton_density_arr, 'tilt_angle': tilt_angle_arr})\n",
    "\n",
    "\n",
    "    with open(f'/home/sachin/Documents/NIPR/Research/Data/ML/SMRAI3/smrai3_scaler_{feat}_{hemi}_id{id}.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    #col_names = df.columns\n",
    "    norm_arr = scaler.transform(df)\n",
    "    #df_proc = pd.DataFrame(norm_arr, columns=col_names)\n",
    "    #df_proc = df_proc.to_numpy()\n",
    "\n",
    "    def create_sequences(arr, lb):\n",
    "        X = []\n",
    "        for i in range(len(arr) - lb):\n",
    "            X.append(arr[i:i+lb].T)\n",
    "\n",
    "        X = np.array(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    proc_seq = create_sequences(norm_arr, lookback)\n",
    "    proc_seq = torch.tensor(proc_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(proc_seq)):\n",
    "            pred = model(proc_seq[i].unsqueeze(0))\n",
    "            predictions.append(pred)\n",
    "\n",
    "    predictions = torch.cat(predictions)\n",
    "    predictions = predictions.to('cpu').numpy()\n",
    "\n",
    "    predictions = predictions.reshape(40,140)\n",
    "    #predictions = np.flipud(predictions)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "make_predictions(NH_fac_model,'fac','NH', -5, 5, 2) #0,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/sachin/miniconda3/envs/torch_env/lib/python3.12/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feat = 'pot'\n",
    "id = 2\n",
    "model = NH_pot_model\n",
    "\n",
    "neg_y_pos_z_nh = make_predictions(model,feat,'NH', -5, 5, id) #0,0\n",
    "neu_y_pos_z_nh = make_predictions(model,feat,'NH', 0, 5, id) #0,1\n",
    "pos_y_pos_z_nh = make_predictions(model,feat,'NH', 5, 5, id) #0,2\n",
    "\n",
    "neg_y_neu_z_nh = make_predictions(model,feat,'NH', -5, 0, id) #1,0\n",
    "neu_y_neu_z_nh = make_predictions(model,feat,'NH', 0, 0, id) #1,1\n",
    "pos_y_neu_z_nh = make_predictions(model,feat,'NH', 5, 0, id) #1,2\n",
    "\n",
    "neg_y_neg_z_nh = make_predictions(model,feat,'NH', -5, -5, id) #2,0\n",
    "neu_y_neg_z_nh = make_predictions(model,feat,'NH', 0, -5, id) #2,1\n",
    "pos_y_neg_z_nh = make_predictions(model,feat,'NH', 5, -5, id) #2,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53061/3253781978.py:36: DeprecationWarning: `interp2d` is deprecated in SciPy 1.10 and will be removed in SciPy 1.14.0.\n",
      "\n",
      "For legacy code, nearly bug-for-bug compatible replacements are\n",
      "`RectBivariateSpline` on regular grids, and `bisplrep`/`bisplev` for\n",
      "scattered 2D data.\n",
      "\n",
      "In new code, for regular grids use `RegularGridInterpolator` instead.\n",
      "For scattered data, prefer `LinearNDInterpolator` or\n",
      "`CloughTocher2DInterpolator`.\n",
      "\n",
      "For more details see\n",
      "`https://scipy.github.io/devdocs/notebooks/interp_transition_guide.html`\n",
      "\n",
      "  f = interpolate.interp2d(x, y, areas, kind='linear')\n",
      "/tmp/ipykernel_53061/3253781978.py:39: DeprecationWarning: `interp2d` is deprecated in SciPy 1.10 and will be removed in SciPy 1.14.0.\n",
      "\n",
      "For legacy code, nearly bug-for-bug compatible replacements are\n",
      "`RectBivariateSpline` on regular grids, and `bisplrep`/`bisplev` for\n",
      "scattered 2D data.\n",
      "\n",
      "In new code, for regular grids use `RegularGridInterpolator` instead.\n",
      "For scattered data, prefer `LinearNDInterpolator` or\n",
      "`CloughTocher2DInterpolator`.\n",
      "\n",
      "For more details see\n",
      "`https://scipy.github.io/devdocs/notebooks/interp_transition_guide.html`\n",
      "\n",
      "  areas = f(xnew, ynew)\n"
     ]
    }
   ],
   "source": [
    "mlat = np.linspace(50, 90, 40)\n",
    "mlt = np.linspace(0, 360, 140)\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    radius = 6371.008 * 1000 #km to m\n",
    "\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    delta_x = dlat * radius #111.32 km per degree\n",
    "    delta_y = dlon * radius * np.cos(np.radians(lat1)) \n",
    "\n",
    "    #area = delta_x * delta_y\n",
    "    #avg_lat = np.radians(lat1 + lat2) / 2\n",
    "    #area = radius**2 *  dlat * dlon * np.cos(avg_lat)\n",
    "    area = radius**2 * (np.sin(np.radians(lat2)) - np.sin(np.radians(lat1))) * (np.radians(lon2) - np.radians(lon1))\n",
    "    \n",
    "    return delta_x, delta_y, area\n",
    "\n",
    "def calculate_delta(mlat, mlt):\n",
    "    #loop through lat and lon and calculate distance between each point\n",
    "    delta_x = np.zeros((len(mlat) - 1, len(mlt) - 1))\n",
    "    delta_y = np.zeros((len(mlat) - 1, len(mlt) - 1))\n",
    "    areas = np.zeros((len(mlat) - 1, len(mlt) - 1))\n",
    "    for i in range(len(mlat) - 1):\n",
    "        for j in range(len(mlt) - 1):\n",
    "            lat1, lat2 = mlat[i], mlat[i + 1]\n",
    "            lon1, lon2 = mlt[j], mlt[j + 1]\n",
    "\n",
    "            dx, dy, area = calculate_distance(lat1, lon1, lat2, lon2)\n",
    "            delta_x[i, j] = dx\n",
    "            delta_y[i, j] = dy\n",
    "            areas[i, j] = area\n",
    "\n",
    "    x = np.arange(areas.shape[1])\n",
    "    y = np.arange(areas.shape[0])\n",
    "    f = interpolate.interp2d(x, y, areas, kind='linear')\n",
    "    xnew = np.arange(0, areas.shape[1], areas.shape[1]/(areas.shape[1]+1))\n",
    "    ynew = np.arange(0, areas.shape[0], areas.shape[0]/(areas.shape[0]+1))\n",
    "    areas = f(xnew, ynew)\n",
    "\n",
    "    return areas\n",
    "\n",
    "areas = calculate_delta(mlat, mlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_y_pos_z_int_nh = np.sum(np.abs(neg_y_pos_z_nh) * areas) / 1e12\n",
    "neu_y_pos_z_int_nh = np.sum(np.abs(neu_y_pos_z_nh) * areas) / 1e12\n",
    "pos_y_pos_z_int_nh = np.sum(np.abs(pos_y_pos_z_nh) * areas) / 1e12\n",
    "neg_y_neu_z_int_nh = np.sum(np.abs(neg_y_neu_z_nh) * areas) / 1e12\n",
    "neu_y_neu_z_int_nh = np.sum(np.abs(neu_y_neu_z_nh) * areas) / 1e12\n",
    "pos_y_neu_z_int_nh = np.sum(np.abs(pos_y_neu_z_nh) * areas) / 1e12\n",
    "neg_y_neg_z_int_nh = np.sum(np.abs(neg_y_neg_z_nh) * areas) / 1e12\n",
    "neu_y_neg_z_int_nh = np.sum(np.abs(neu_y_neg_z_nh) * areas) / 1e12\n",
    "pos_y_neg_z_int_nh = np.sum(np.abs(pos_y_neg_z_nh) * areas) / 1e12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_dict_nh = {'neg_y_pos_z': neg_y_pos_z_int_nh, 'neu_y_pos_z': neu_y_pos_z_int_nh, 'pos_y_pos_z': pos_y_pos_z_int_nh, 'neg_y_neu_z': neg_y_neu_z_int_nh, 'neu_y_neu_z': neu_y_neu_z_int_nh, 'pos_y_neu_z': pos_y_neu_z_int_nh, 'neg_y_neg_z': neg_y_neg_z_int_nh, 'neu_y_neg_z': neu_y_neg_z_int_nh, 'pos_y_neg_z': pos_y_neg_z_int_nh}\n",
    "#int_dict_sh = {'neg_y_pos_z': neg_y_pos_z_int_sh, 'neu_y_pos_z': neu_y_pos_z_int_sh, 'pos_y_pos_z': pos_y_pos_z_int_sh, 'neg_y_neu_z': neg_y_neu_z_int_sh, 'neu_y_neu_z': neu_y_neu_z_int_sh, 'pos_y_neu_z': pos_y_neu_z_int_sh, 'neg_y_neg_z': neg_y_neg_z_int_sh, 'neu_y_neg_z': neu_y_neg_z_int_sh, 'pos_y_neg_z': pos_y_neg_z_int_sh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3,figsize=(10, 10), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Define radial and angular coordinates\n",
    "theta = np.linspace(0, 360, 140) - 90\n",
    "theta_rad = np.deg2rad(theta)\n",
    "r = 90 - np.linspace(50, 90, 40)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.65)\n",
    "vmin = -50\n",
    "vmax = 50\n",
    "\n",
    "# Plot the data\n",
    "plots = [\n",
    "    ax[0,0].pcolormesh(theta_rad, r, neg_y_pos_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[0,1].pcolormesh(theta_rad, r, neu_y_pos_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[0,2].pcolormesh(theta_rad, r, pos_y_pos_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[1,0].pcolormesh(theta_rad, r, neg_y_neu_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[1,1].pcolormesh(theta_rad, r, neu_y_neu_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[1,2].pcolormesh(theta_rad, r, pos_y_neu_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[2,0].pcolormesh(theta_rad, r, neg_y_neg_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[2,1].pcolormesh(theta_rad, r, neu_y_neg_z_nh, cmap='bwr', vmin=vmin, vmax=vmax),\n",
    "    ax[2,2].pcolormesh(theta_rad, r, pos_y_neg_z_nh, cmap='bwr', vmin=vmin, vmax=vmax)\n",
    "]\n",
    "\n",
    "#subplot titles\n",
    "ax[0,0].set_title('-Y +Z', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[0,1].set_title('+Z', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[0,2].set_title('+Y +Z', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[1,0].set_title('-Y', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[1,1].set_title('Zero', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[1,2].set_title('+Y', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[2,0].set_title('-Y -Z', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[2,1].set_title('-Z', fontsize=10, pad=10.5, fontweight='bold')\n",
    "ax[2,2].set_title('+Y -Z', fontsize=10, pad=10.5, fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "'''nhsh_ratio = r'$\\frac{in}{out}$'\n",
    "ax[0,0].annotate(f'{nhsh_ratio}: {neg_y_pos_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[0,1].annotate(f'{nhsh_ratio}: {neu_y_pos_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[0,2].annotate(f'{nhsh_ratio}: {pos_y_pos_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,0].annotate(f'{nhsh_ratio}: {neg_y_neu_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,1].annotate(f'{nhsh_ratio}: {neu_y_neu_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,2].annotate(f'{nhsh_ratio}: {pos_y_neu_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,0].annotate(f'{nhsh_ratio}: {neg_y_neg_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,1].annotate(f'{nhsh_ratio}: {neu_y_neg_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,2].annotate(f'{nhsh_ratio}: {pos_y_neg_z_ratio:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)'''\n",
    "\n",
    "'''#day night ratio\n",
    "ax[0,0].annotate(f'D/N: {neg_y_pos_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[0,1].annotate(f'D/N: {neu_y_pos_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[0,2].annotate(f'D/N: {pos_y_pos_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,0].annotate(f'D/N: {neg_y_neu_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,1].annotate(f'D/N: {neu_y_neu_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,2].annotate(f'D/N: {pos_y_neu_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,0].annotate(f'D/N: {neg_y_neg_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,1].annotate(f'D/N: {neu_y_neg_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,2].annotate(f'D/N: {pos_y_neg_z_daynight:.1f}', xy=(1.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)'''\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].set_ylim([0, 37])\n",
    "        ax[i, j].set_yticks([0, 10, 20, 30])\n",
    "        ax[i, j].set_yticklabels([\"90°\", \"80°\", \"70°\", \"60° MLAT\"])\n",
    "        ax[i, j].set_xlim([-np.pi, np.pi])\n",
    "        ax[i, j].set_xticks(np.linspace(-np.pi, np.pi, 9)[1:])\n",
    "        ax[i, j].set_xticklabels([\"21\", \"0 MLT \\nMidnight\", \"3\", \"6 \\n  Dawn\", \"9\", \"12 MLT \\nMidday\", \"15\", \"18 \\nDusk\"])\n",
    "        ax[i, j].grid(True, linestyle='-', linewidth=0.5, zorder=6)\n",
    "\n",
    "# Define the position for the colorbar manually\n",
    "cbar_ax = fig.add_axes([0.425, 0.04, 0.18, 0.01])  # [left, bottom, width, height]\n",
    "\n",
    "# Add the colorbar\n",
    "if feat == 'fac':\n",
    "    fig.colorbar(plots[-1], cax=cbar_ax, label='FAC / J$_\\parallel$ [µA/m$^2$]', \n",
    "                orientation='horizontal', ticks=[-1, -0.5, 0, 0.5, 1], \n",
    "                extend='both')\n",
    "    units = 'MA'\n",
    "elif feat == 'pot':\n",
    "    fig.colorbar(plots[-1], cax=cbar_ax, label='Potential [kV]', \n",
    "                orientation='horizontal', ticks=[-50, -25, 0, 25, 50], \n",
    "                extend='both')\n",
    "    units = 'kV'\n",
    "else:\n",
    "    fig.colorbar(plots[-1], cax=cbar_ax, label='Potential [kV]', \n",
    "                orientation='horizontal', ticks=[0, 5, 10, 15, 20], \n",
    "                extend='both')\n",
    "    units = 'S/m'    \n",
    "    \n",
    "ax[0,0].annotate(f'$\\int$: {neg_y_pos_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[0,1].annotate(f'$\\int$: {neu_y_pos_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[0,2].annotate(f'$\\int$: {pos_y_pos_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,0].annotate(f'$\\int$: {neg_y_neu_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,1].annotate(f'$\\int$: {neu_y_neu_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[1,2].annotate(f'$\\int$: {pos_y_neu_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,0].annotate(f'$\\int$: {neg_y_neg_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,1].annotate(f'$\\int$: {neu_y_neg_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "ax[2,2].annotate(f'$\\int$: {pos_y_neg_z_int_nh:.1f} {units}', xy=(-0.05, 1.12), xycoords='axes fraction', ha='center', va='center', fontsize=10.5)\n",
    "\n",
    "\n",
    "#control width between plots\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('lstm_9panel_NH.png', dpi=500, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
